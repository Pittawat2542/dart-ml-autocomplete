{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC532_Term_Project_RNN_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkpy5HmRVW6f"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImsU9tObaOl1"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import time\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "douLYxSGhZkC"
      },
      "source": [
        "file_name = 'source_code.txt'\n",
        "file_url = 'https://github.com/Pittawat2542/dart-ml-autocomplete/raw/master/dataset_collector/source_code.txt'\n",
        "r = requests.get(file_url, allow_redirects=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Ft_jynhnUc",
        "outputId": "8a05fdb2-5789-478b-d7af-0560ed5e4b75"
      },
      "source": [
        "open(file_name, 'wb').write(r.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5148815"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRC5z2M_mi2K",
        "outputId": "e19ddd0d-161f-44f1-bdeb-bac2d95cbfa0"
      },
      "source": [
        "text = open(file_name, 'rb').read().decode(encoding='utf-8')\n",
        "text = re.sub(r\"//.*\", \"\", text) # remove comment\n",
        "text = re.sub(r\"import.*\", \"\", text) # remove import\n",
        "text = re.sub(r\"export.*\", \"\", text) # remove export\n",
        "text = re.sub(r\"^(?:[\\t ]*(?:\\r?\\n|\\r))+\", \"\", text) # remove blank line\n",
        "text = re.sub(r\"^(\\s*\\r\\n){2,}\", \"\\r\\n\", text) # replace multiple blank lines with one\n",
        "text = re.sub(r\"^\\s*$\", \"\", text) # remove line with only spaces\n",
        "text = text.replace('\\n', '').replace(';', ';\\n')\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 4130705 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3iaZxrDmkm_",
        "outputId": "c3e78686-8489-4d25-fc8b-8800029ad33f"
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final Context posix = Context(style: Style.posix);\n",
            "final Context windows = Context(style: Style.windows);\n",
            "final Context url = Context(style: Style.url);\n",
            "final Context context = createInternal();\n",
            "Style get style => context.style;\n",
            "String get current { \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDfoyU0Pmm4L",
        "outputId": "58bf4372-38c6-4b10-f8dc-197bfb4cfd20"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1114 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRN9MWVvmnRi",
        "outputId": "e1ceed77-1f52-403e-dced-7e387bb3542f"
      },
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4lIvrcEmoxq"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDCy4GzlmqS4",
        "outputId": "a3fbcdb0-983d-45bd-e2a5-2601895f6440"
      },
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[68, 69, 70, 71, 72, 73, 74], [91, 92, 93]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy5HJ_camsdO"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2De30JpImsWA",
        "outputId": "e4680b89-2373-43e9-f428-0e3dd1ec2305"
      },
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wQnQ6G_mvXO",
        "outputId": "22c2020d-51d2-4200-81b1-6f68b3148fe6"
      },
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujjObS4smvxx"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRU6cZUEmwKO",
        "outputId": "89eb9386-87cc-4a87-9217-bccc08fad472"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4130705,), dtype=int64, numpy=array([73, 76, 81, ..., 30,  2, 96])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTJgh-Whm0Pz"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK5bEJOim1gT",
        "outputId": "2cd95947-a273-43f2-c8ba-d66e5f459dbe"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f\n",
            "i\n",
            "n\n",
            "a\n",
            "l\n",
            " \n",
            "C\n",
            "o\n",
            "n\n",
            "t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90aect3Xm3Dd"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn4pYD3Bm4bi",
        "outputId": "b3d09d47-9953-432c-f502-08039d4c3fd8"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'f' b'i' b'n' b'a' b'l' b' ' b'C' b'o' b'n' b't' b'e' b'x' b't' b' '\n",
            " b'p' b'o' b's' b'i' b'x' b' ' b'=' b' ' b'C' b'o' b'n' b't' b'e' b'x'\n",
            " b't' b'(' b's' b't' b'y' b'l' b'e' b':' b' ' b'S' b't' b'y' b'l' b'e'\n",
            " b'.' b'p' b'o' b's' b'i' b'x' b')' b';' b'\\n' b'f' b'i' b'n' b'a' b'l'\n",
            " b' ' b'C' b'o' b'n' b't' b'e' b'x' b't' b' ' b'w' b'i' b'n' b'd' b'o'\n",
            " b'w' b's' b' ' b'=' b' ' b'C' b'o' b'n' b't' b'e' b'x' b't' b'(' b's'\n",
            " b't' b'y' b'l' b'e' b':' b' ' b'S' b't' b'y' b'l' b'e' b'.' b'w' b'i'\n",
            " b'n' b'd' b'o'], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz0rH9k-m6Xp",
        "outputId": "744b467e-271b-482f-e0a1-7595c7e14725"
      },
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'final Context posix = Context(style: Style.posix);\\nfinal Context windows = Context(style: Style.windo'\n",
            "b'ws);\\nfinal Context url = Context(style: Style.url);\\nfinal Context context = createInternal();\\nStyle g'\n",
            "b'et style => context.style;\\nString get current {          Uri uri;\\n  try {    uri = Uri.base;\\n  } on E'\n",
            "b'xception {    if (_current != null) return _current!;\\n    rethrow;\\n  }      if (uri == _currentUriBas'\n",
            "b'e) return _current!;\\n  _currentUriBase = uri;\\n  if (Style.platform == Style.url) {    _current = uri.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL5N7rdwm8ci"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSIMe4MBm-W9",
        "outputId": "86541890-d9c0-4c3c-c60a-2cbecaca300d"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0RegvNnm_1S"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkJZ5uwJnBZC",
        "outputId": "9f8729dc-d10f-4d70-9a1b-458ef5a70c32"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'final Context posix = Context(style: Style.posix);\\nfinal Context windows = Context(style: Style.wind'\n",
            "Target: b'inal Context posix = Context(style: Style.posix);\\nfinal Context windows = Context(style: Style.windo'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSFYYHKsnDnN",
        "outputId": "ef2692de-86c1-48ee-fa88-ea15c6cd43ec"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSRUl6oHVVHK"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJqP-3krnE0k"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf4DiKppnIzx"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else: \n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wEJMQXwnMCW"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y82F_fKonNwM",
        "outputId": "279a0026-76ce-4f7a-9a9a-a718b6089b64"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 1116) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMYH_s7unNqj",
        "outputId": "2165a442-cbc0-49f7-b19c-e98c99c2f5d4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  285696    \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  1143900   \n",
            "=================================================================\n",
            "Total params: 5,367,900\n",
            "Trainable params: 5,367,900\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtRv8lPwnPfg"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDXEVrm9nRTL",
        "outputId": "bba97327-cc3a-433c-e08a-d8f7340f0aaa"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 281,  699,  842,  635,  581, 1073, 1058,   73,  305,  591,  830,\n",
              "        151,  995,  378, 1052,  554,  909,  642,  717,  739,  600,  547,\n",
              "        162,  745, 1102,  377, 1040,  589,  439,   50,  721,  427,  265,\n",
              "        462,    7,  316,  432,  684,  779,  123,  305,  264,  969, 1005,\n",
              "        140,  348,  979,  999,  180,  145,  241, 1006,  611,  634,  860,\n",
              "        580,  131,  416,  455,  617,  395,  520,  480,  266,  561,  828,\n",
              "       1075,  608,  772,  407,  481,  896, 1083,  692,  709,  971, 1033,\n",
              "        520, 1109,  467,  479,  494,   61,   82,  460,  631,  102,  700,\n",
              "        799,  116,  713,  505,  151,  905,  788,  622,  686,  126,  156,\n",
              "        690])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8eBCLUWnTb8",
        "outputId": "a2fc3779-5d74-4916-c1b5-a3dffa47beae"
      },
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b\"zz',         'ZZZZ': 'ZZZZ'       },            'sq': const {        'd': 'd',         'E': 'ccc',  \"\n",
            "\n",
            "Next Char Predictions:\n",
            " b'\\xd4\\xbf\\xe0\\xb4\\x95\\xe1\\x80\\x81\\xe0\\xb0\\xa4\\xe0\\xac\\xbe\\xe5\\x9c\\x9f\\xe4\\xb8\\x8bf\\xd5\\xb7\\xe0\\xae\\x85\\xe0\\xba\\xb5\\xc5\\x9e\\xe1\\x8f\\x98\\xd9\\xbe\\xe2\\x80\\xa2\\xe0\\xac\\x86\\xe1\\x88\\x8b\\xe0\\xb0\\xae\\xe0\\xb4\\xb0\\xe0\\xb5\\xbe\\xe0\\xae\\x9e\\xe0\\xab\\x80\\xc9\\x94\\xe0\\xb6\\x9f\\xec\\x8b\\x9c\\xd9\\x94\\xe1\\x9f\\x8d\\xe0\\xad\\x8d\\xe0\\xa5\\x8dO\\xe0\\xb4\\xb4\\xe0\\xa4\\xb9\\xd1\\x98\\xe0\\xa6\\xaa$\\xd6\\x82\\xe0\\xa5\\x81\\xe0\\xb2\\xbe\\xe0\\xb8\\x96\\xc3\\xbb\\xd5\\xb7\\xd1\\x97\\xe1\\x8e\\xab\\xe1\\x9e\\x80\\xc4\\xa7\\xd8\\xa3\\xe1\\x8e\\xbe\\xe1\\x8f\\xa2\\xce\\xa7\\xc5\\x82\\xd0\\xba\\xe1\\x9e\\x82\\xe0\\xae\\xb2\\xe0\\xb0\\xa1\\xe1\\x80\\x9c\\xe0\\xac\\xb8\\xc4\\x8b\\xe0\\xa4\\xab\\xe0\\xa6\\x9f\\xe0\\xae\\xbf\\xe0\\xa4\\x82\\xe0\\xaa\\x87\\xe0\\xa7\\x83\\xd1\\x99\\xe0\\xac\\x9c\\xe0\\xba\\xb2\\xe5\\xb9\\xb4\\xe0\\xae\\xaf\\xe0\\xb8\\x84\\xe0\\xa4\\x9c\\xe0\\xa7\\x87\\xe1\\x83\\x9e\\xe6\\x9b\\x9c\\xe0\\xb3\\x8d\\xe0\\xb4\\xa6\\xe1\\x8e\\xad\\xe1\\x9e\\xbb\\xe0\\xaa\\x87\\xec\\xa0\\x9c\\xe0\\xa6\\xaf\\xe0\\xa7\\x82\\xe0\\xa8\\xa6Zo\\xe0\\xa6\\xa7\\xe0\\xb0\\x9a\\xc3\\x9a\\xe0\\xb4\\x97\\xe0\\xb8\\xb1\\xc3\\xae\\xe0\\xb4\\xab\\xe0\\xa8\\xb9\\xc5\\x9e\\xe1\\x83\\xab\\xe0\\xb8\\xa2\\xe0\\xaf\\x88\\xe0\\xb3\\x81\\xc3\\xbe\\xc5\\xab\\xe0\\xb3\\x88'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JRElB1FnV87"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkk1CoynnXVy",
        "outputId": "db996bd4-7a48-4d4b-ab74-7101c94fb736"
      },
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 1116)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         7.0169463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-geu3DxnYt3",
        "outputId": "c6bd483a-a7c5-4a89-d037-d441e7e6e67b"
      },
      "source": [
        "tf.exp(mean_loss).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115.3754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZlVwOYWnZ5b"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7odN7R1DnbCq"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOm4T0AkndGM"
      },
      "source": [
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhQWCtg5neam",
        "outputId": "fe449041-ba70-4786-d4a2-d0beab51e9bd"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "639/639 [==============================] - 49s 74ms/step - loss: 2.3028\n",
            "Epoch 2/20\n",
            "639/639 [==============================] - 46s 70ms/step - loss: 0.8565\n",
            "Epoch 3/20\n",
            "639/639 [==============================] - 47s 72ms/step - loss: 0.5984\n",
            "Epoch 4/20\n",
            "639/639 [==============================] - 46s 71ms/step - loss: 0.4841\n",
            "Epoch 5/20\n",
            "639/639 [==============================] - 47s 72ms/step - loss: 0.4185\n",
            "Epoch 6/20\n",
            "639/639 [==============================] - 46s 71ms/step - loss: 0.3731\n",
            "Epoch 7/20\n",
            "639/639 [==============================] - 47s 71ms/step - loss: 0.3451\n",
            "Epoch 8/20\n",
            "639/639 [==============================] - 47s 71ms/step - loss: 0.3230\n",
            "Epoch 9/20\n",
            "639/639 [==============================] - 47s 71ms/step - loss: 0.3035\n",
            "Epoch 10/20\n",
            "639/639 [==============================] - 47s 72ms/step - loss: 0.2918\n",
            "Epoch 11/20\n",
            "639/639 [==============================] - 47s 72ms/step - loss: 0.2800\n",
            "Epoch 12/20\n",
            "639/639 [==============================] - 47s 72ms/step - loss: 0.2720\n",
            "Epoch 13/20\n",
            "639/639 [==============================] - 47s 71ms/step - loss: 0.2640\n",
            "Epoch 14/20\n",
            "639/639 [==============================] - 47s 72ms/step - loss: 0.2602\n",
            "Epoch 15/20\n",
            "639/639 [==============================] - 47s 72ms/step - loss: 0.2541\n",
            "Epoch 16/20\n",
            "639/639 [==============================] - 47s 72ms/step - loss: 0.2512\n",
            "Epoch 17/20\n",
            "639/639 [==============================] - 47s 72ms/step - loss: 0.2491\n",
            "Epoch 18/20\n",
            "639/639 [==============================] - 47s 71ms/step - loss: 0.2474\n",
            "Epoch 19/20\n",
            "639/639 [==============================] - 47s 71ms/step - loss: 0.2495\n",
            "Epoch 20/20\n",
            "639/639 [==============================] - 47s 72ms/step - loss: 0.2457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdGnm4GPVOa6"
      },
      "source": [
        "# Pilot Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME1tBgS7nfvf"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature=temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['','[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices = skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())]) \n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits] \n",
        "    predicted_logits, states =  self.model(inputs=input_ids, states=states, \n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "336oiUxynfo3"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYwwG_QsnkNq",
        "outputId": "745f7db0-eb76-4799-9dac-fee2dbdcc842"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['const'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(30):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "\n",
        "print(f\"\\nRun time: {end - start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "const IconDataBrands(0xf8d6);\n",
            "      \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.7518947124481201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtmfKNRynl1T",
        "outputId": "18064c62-684e-4df1-f7c7-9c8cc4c4bd39"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['const', 'const', 'const', 'const', 'const'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "\n",
        "\n",
        "print(f\"\\nRun time: {end - start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'const IconData solidThardoNest = const IconDataSolid(0xf104);\\n          static const IconData grintVide = const IconDataSolid(0xf782);\\n        static const IconData fistyl = const IconDataBrands(0xf16c);\\n          static const IconData biandixcletPressink = const IconDataSolid(0xf2b5);\\n          static const IconData shildTieg = const IconDataSolid(0xf644);\\n          static const IconData anglehter = const IconDataSolid(0xf4b5);\\n        static const IconData doatsbill = const IconDataBrands(0xe084);\\n        static const IconData redivi = const IconDataBrands(0xf283);\\n        static const IconData barcent = const IconDataBrands(0xf784);\\n          static const IconData sneploa = const IconDataSolid(0xf75e);\\n        static const IconData microshte = const IconDataSolid(0xf466);\\n          static const IconData sortAmountFiarkRight = const IconDataSolid(0xe06a);\\n        static const IconData kisz = const IconDataBrands(0xf4eb);\\n        static const IconData noCHambos = const IconDataBrands(0xf2b'\n",
            " b'const IconData angleNameste = const IconDataRegular(0xf192);\\n          static const IconData solidHandRock = const IconDataSolid(0xf4d0);\\n          static const IconData stackLister = const IconDataSolid(0xf29c);\\n          static const IconData syec = const IconDataSolid(0xf541);\\n          static const IconData jedrustdire = const IconDataSolid(0xf65c);\\n          static const IconData sustAmesherFile = const IconDataSolid(0xf03a);\\n          static const IconData mouseCellSpound = const IconDataSolid(0xf4b6);\\n          static const IconData handPointType = const IconDataSolid(0xf56c);\\n          static const IconData dusinsSquare3ceStrixTwrirsValu = const IconDataSolid(0xf794);\\n          static const IconData userAddrisquiraRight = const IconDataRegular(0xf02e);\\n          static const IconData solidHandRock = const IconDataSolid(0xf741);\\n          static const IconData unlascriptisquare = const IconDataSolid(0xf249);\\n          static const IconData firecoxtit = const IconDataSolid(0xf27a);\\n  '\n",
            " b\"const [            'domingo',            'lundo',            'marte',            'mi\\xc3\\xa9.',            'join',            'viernes',            's\\xc3\\xa1bado'          ],          STANDALONESHORTWEEKDAYS: const [            'Sal',            'Fri',            'Sat'          ],          NARROWWEEKDAYS: const [        'Su': 'LLLL',         'M': 'M/y',         'yMd': 'M/d',         'MEEEE': 'cccc',         'LLLL': 'LLLL',         'M': 'M/y',         'Md': 'M/d',         'MEd': 'EEE, M/d',         'MMM': 'LLL',         'MEd': 'MM-dd MMM',         'MMMEd': 'M. d. EEE',         'MMMM': 'LLLL',         'MMMMd': 'MMMM d',         'MMMMEEEEd': 'EEEE, MMMM',         'QQQ': 'QQQ',         'QQQQ': 'QQQQ',         'y': 'y',         'yM': 'M.y',         'yMd': 'dd-MM.',         'yMd': 'dd.MM.y',         'yMEd': 'd.MM.y \\xd5\\xa9. LEz',         'yQQQ': 'y-\\\\'\\xd0\\xb6\\\\'. QQQ',         'yQQQQ': 'y \\\\'m\\\\'. LLLL',         'yQQQ': 'y-\\\\',         'yQQQQ': 'y \\\\'m\\\\'.QQQQ',         'H': 'HH',         'Hm': 'HH:mm',         'Hms': 'HH:mm:ss\"\n",
            " b'const IconData knankum = const IconDataBrands(0xf429);\\n        static const IconData layleh = const IconDataBrands(0xf209);\\n        static const IconData borderNane = const IconDataBrands(0xf372);\\n        static const IconData skitch = const IconDataBrands(0xf2d7);\\n        static const IconData laptopToxy = const IconDataBrands(0xf78b);\\n        static const IconData solidbase = const IconDataSolid(0xe033);\\n          static const IconData squarderAlt = const IconDataSolid(0xf023);\\n          static const IconData aunglebasce = const IconDataSolid(0xf8c6);\\n          static const IconData souilEark = const IconDataSolid(0xf0e7);\\n          static const IconData keymatchan = const IconDataSolid(0xf5a8);\\n          static const IconData skull = const IconDataSolid(0xf1e4);\\n          static const IconData markiHmard quirksh = const IconDataSolid(0xf0e7);\\n        static const IconData egrams = const IconDataBrands(0xf400);\\n          static const IconData fillkBant = const IconDataSolid(0xf1eb);\\n     '\n",
            " b\"const IconDataSolid(0xf4b2);\\n          static const IconData yesSignnoreAll = const IconDataSolid(0xf283);\\n          static const IconData avogiaTextSquare = const IconDataSolid(0xf020);\\n          static const IconData shareAlt = const IconDataSolid(0xf2c9);\\n          static const IconData tharAid = const IconDataSolid(0xf77b);\\n        static const IconData playebafs = const IconDataBrands(0xf1f1);\\n        static const IconData ewave = const IconttextStyle,      fontFamily: 'Fahkwang',      color: color,      backgroundColor: backgroundColor,      fontStyle: fontStyle,      letterSpacing: letterSpacing,      wordSpacing: wordSpacing,      textBaseline: textBaseline,      height: height,      locale: locale,      foreground: foreground,      background: background,      shadows: shadows,      fontFeatures: fontFeatures,      decoration: decoration,      decorationColor: decorationColor,      decorationStyle: decorationStyle,      decorationThickness: decorationThickness,      fonts: fonts,  \"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.6486332416534424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-_XErgBVL1l"
      },
      "source": [
        "# Exporting Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwMMJvQwnndQ",
        "outputId": "3d20954e-1f69-45e9-91d3-1ce88121e525"
      },
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7fb5e83498d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JoKAXeITw6s"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "    \n",
        "def zipdir(path, ziph):\n",
        "    # ziph is zipfile handle\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            ziph.write(os.path.join(root, file), \n",
        "                       os.path.relpath(os.path.join(root, file), \n",
        "                                       os.path.join(path, '..')))\n",
        "      \n",
        "zipf = zipfile.ZipFile('model.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "zipdir('one_step/', zipf)\n",
        "zipf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWoJC8WYVJ9y"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERLjXi81Tyf1",
        "outputId": "b460e183-ba5e-443b-bd33-1106207ec858"
      },
      "source": [
        "import requests\n",
        "\n",
        "file_name = 'rnn_model_v2.zip'\n",
        "file_url = 'https://github.com/Pittawat2542/dart-ml-autocomplete/raw/master/rnn_model_v2.zip'\n",
        "r = requests.get(file_url, allow_redirects=True)\n",
        "open(file_name, 'wb').write(r.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59907559"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPDHyV2LT8nG",
        "outputId": "c7ea45fc-ec2e-4298-c059-cc6d87bd4515"
      },
      "source": [
        "!unzip rnn_model_v2.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  rnn_model_v2.zip\n",
            "  inflating: one_step/saved_model.pb  \n",
            "  inflating: one_step/variables/variables.data-00000-of-00001  \n",
            "  inflating: one_step/variables/variables.index  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbCf7zrjTv3i"
      },
      "source": [
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vK19cNenpZh",
        "outputId": "624a6f98-98bf-42a6-ca1d-1623ce65b548"
      },
      "source": [
        "states = None\n",
        "next_char = tf.constant(['const'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f5370c63710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f5370c63710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "const IconData boikAlt = const IconDataSolid(0xf2c4);\n",
            "          static const IconData solidWindowSlash = \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}